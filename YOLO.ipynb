{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drUortcSMBU8"
   },
   "source": [
    "Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2hBd7OGjWfV9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "from google.colab.patches import cv2_imshow\n",
    "from pycocotools.coco import COCO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление гугл диска для хранения датасетов и другой необходимой информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NPXCAOgVbZG"
   },
   "outputs": [],
   "source": [
    "def mount_drive():\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"Google Drive смонтирован\")\n",
    "    else:\n",
    "        print(\"Google Drive уже подключен\")\n",
    "\n",
    "mount_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Директории для хранения датасета, модели и папок с изображениями для обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X03rmjiJVbh1"
   },
   "outputs": [],
   "source": [
    "MAIN = '/content/drive/MyDrive/YOLO_COCO'\n",
    "DATASET = os.path.join(MAIN, 'dataset')\n",
    "ANNOTATIONS = os.path.join(DATASET, 'annotations')\n",
    "MODEL = os.path.join(MAIN, 'model')\n",
    "INPUT = '/content/input'\n",
    "RESULT = '/content/result'\n",
    "CROPPED = '/content/cropped'\n",
    "os.makedirs(ANNOTATIONS, exist_ok=True)\n",
    "os.makedirs(MODEL, exist_ok=True)\n",
    "os.makedirs(INPUT, exist_ok=True)\n",
    "os.makedirs(RESULT, exist_ok=True)\n",
    "os.makedirs(CROPPED, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем есть ли датасет в директории, если нет начинаем загрузку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfXn_VShVbqV"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    required_files = {\n",
    "        'train': 'instances_train2017.json',\n",
    "        'val': 'instances_val2017.json'\n",
    "    }\n",
    "    if not all(os.path.exists(os.path.join(ANNOTATIONS, f)) for f in required_files.values()):\n",
    "        print(\"Загрузка датасета\")\n",
    "        !wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P {DATASET}\n",
    "        !unzip -qo {DATASET}/annotations_trainval2017.zip -d {DATASET}\n",
    "        !rm {DATASET}/annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевые классы (изменить) и работа с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVaJfra2Vbww"
   },
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['aeroplane', 'bird', 'kite']\n",
    "\n",
    "def filter_coco(annotation_path, output):\n",
    "    coco = COCO(annotation_path)\n",
    "    class_ids = coco.getCatIds(catNms=CLASS_NAMES)\n",
    "    img_ids = coco.getImgIds(catIds=class_ids)\n",
    "\n",
    "    new_ann = {\n",
    "        'images': coco.loadImgs(img_ids),\n",
    "        'annotations': coco.loadAnns(coco.getAnnIds(imgIds=img_ids, catIds=class_ids)),\n",
    "        'categories': [c for c in coco.dataset['categories'] if c['name'] in CLASS_NAMES]\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(output, 'filtered_annotations.json'), 'w') as f:\n",
    "        json.dump(new_ann, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка фреймворка даркнет для работы с Yolo, установка зависимостей cuda\n",
    "Добавляем в makefile поддержку gpu opencv и cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqHNfUwdVbzh"
   },
   "outputs": [],
   "source": [
    "def load_yolo():\n",
    "    if not os.path.exists('darknet'):\n",
    "        !git clone https://github.com/AlexeyAB/darknet\n",
    "    %cd darknet\n",
    "    !sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "    !sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "    !sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "    !make\n",
    "    %cd ..\n",
    "    !apt-get install -y --no-install-recommends cuda-toolkit-11-2\n",
    "    !cp darknet/cfg/yolov3-tiny.cfg {MODEL}/yolov3-tiny-custom.cfg\n",
    "    !sed -i 's/classes=80/classes=3/g' {MODEL}/yolov3-tiny-custom.cfg\n",
    "    !sed -i 's/filters=255/filters=24/g' {MODEL}/yolov3-tiny-custom.cfg\n",
    "    with open(f\"{MODEL}/obj.names\", 'w') as f:\n",
    "        f.write('\\n'.join(CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детекция обьектов предобучнной моделью\n",
    "1. Загрузка готовых весов yolo обученных на coco\n",
    "2. Находим указанные классы\n",
    "3. Загружаем модель \n",
    "4. Очищаем результаты предыдущих детекций\n",
    "5. Преобразуем изображение и для каждого предсказанного класса смотрим уверенность\n",
    "5.1 Удаляем повторные ббоксы на одном обьекте с помощью NMS\n",
    "6. Сортируем в зависимости от уверенности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "DLsWV35odZ3S",
    "outputId": "35ca1ff8-f21b-424d-b615-7ef8a8ded54c"
   },
   "outputs": [],
   "source": [
    "def detection():\n",
    "    if not os.path.exists('yolov3-tiny.weights'):\n",
    "        !wget https://pjreddie.com/media/files/yolov3-tiny.weights\n",
    "    with open(\"darknet/data/coco.names\", \"r\") as f:\n",
    "        coco_classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    class_ids = []\n",
    "    for cls in CLASS_NAMES:\n",
    "        if cls in coco_classes:\n",
    "            class_ids.append(coco_classes.index(cls))\n",
    "        else:\n",
    "            print(f\"'{cls}' нет в coco\")\n",
    "\n",
    "    net = cv2.dnn.readNetFromDarknet('darknet/cfg/yolov3-tiny.cfg', 'yolov3-tiny.weights')\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    shutil.rmtree(RESULT, ignore_errors=True)\n",
    "    shutil.rmtree(CROPPED, ignore_errors=True)\n",
    "    os.makedirs(RESULT, exist_ok=True)\n",
    "    os.makedirs(CROPPED, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(INPUT):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(INPUT, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Проблема с файлом {filename}\")\n",
    "                continue\n",
    "            H, W = img.shape[:2]\n",
    "            result = img.copy()\n",
    "            high_confidence = False\n",
    "            blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            outputs = net.forward(ln)\n",
    "            boxes = []\n",
    "            confidences = []\n",
    "            class_ids_detected = []\n",
    "            for i in outputs:\n",
    "                for detection in i:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence > 0.3 and class_id in class_ids: \n",
    "                        box = detection[0:4] * np.array([W, H, W, H])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                        x = max(0, int(centerX - (width / 2)))\n",
    "                        y = max(0, int(centerY - (height / 2)))\n",
    "\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        class_ids_detected.append(class_id)\n",
    "\n",
    "            indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "            print(f\"Изображение: {filename}\")\n",
    "            print(f\"Найдено объектов: {len(indices)}\")\n",
    "            print(f\"Предварительный класс: {class_id}\")\n",
    "            if len(indices) > 0:\n",
    "                for i in indices.flatten():\n",
    "                    x, y, w, h = boxes[i]\n",
    "                    confidence = confidences[i]\n",
    "                    class_name = coco_classes[class_ids_detected[i]]\n",
    "\n",
    "                    if confidence >= 0.7:\n",
    "                        high_confidence = True\n",
    "                        label = f\"{class_name} {confidence:.2f}\"\n",
    "                        color = (0, 255, 0)\n",
    "                        cv2.rectangle(result, (x, y), (x+w, y+h), color, 2)\n",
    "                        cv2.putText(result, label, (x, y-5),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                    else:\n",
    "                        crop = img[y:y+h+30, x:x+w+30]\n",
    "                        crop_filename = f\"{os.path.splitext(filename)[0]}_{i}.jpg\"\n",
    "                        cv2.imwrite(os.path.join(CROPPED, crop_filename), crop)\n",
    "                if high_confidence:\n",
    "                    output_path = os.path.join(RESULT, filename)\n",
    "                    cv2.imwrite(output_path, result)\n",
    "            else:\n",
    "                print(\"Пустое изображение\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для будущего обучения елки\n",
    "Три класса, train.txt список изобдажений для обучения (должны быть указаны пути), val для валидации,names имена классов, backup для сохранения весов во время обучения\n",
    "obj.names создаваться должен по идее при настройке yolo выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYa0vWRtVb-W"
   },
   "outputs": [],
   "source": [
    "def train_yolo():\n",
    "    config = f\"\"\"classes = 3\n",
    "    train = {DATASET}/train.txt\n",
    "    valid = {DATASET}/val.txt\n",
    "    names = {MODEL}/obj.names\n",
    "    backup = {MODEL}/backup\"\"\"\n",
    "    with open(f\"{MODEL}/obj.data\", 'w') as f:\n",
    "        f.write(config)\n",
    "    !./darknet/darknet detector train \\\n",
    "        {MODEL}/obj.data \\\n",
    "        {MODEL}/yolov3-tiny-custom.cfg \\\n",
    "        -dont_show \\\n",
    "        -map \\\n",
    "        -clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск детекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "730YRpviVcAq"
   },
   "outputs": [],
   "source": [
    "load_dataset()\n",
    "filter_coco(os.path.join(ANNOTATIONS, 'instances_train2017.json'), DATASET)\n",
    "load_yolo()\n",
    "detection()\n",
    "options = input(\"Начать обучение(ответить n): \")\n",
    "if options.lower() == 'y':\n",
    "    train_yolo()\n",
    "else:\n",
    "    print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
